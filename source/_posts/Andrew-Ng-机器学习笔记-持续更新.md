---
title: Andrew Ng 机器学习笔记(持续更新)
date: 2022-02-21 19:27:56
categories: 人工智能
excerpt: 大三的寒假即将结束，突然想起来博客很久没更新了，于是特意维护了一下，更新了一些配置。本篇博客是我机器学习课程的笔记，将会持续更新，直到我学习完机器学习课程。
index_img: /img/AI/ai_index.jpg
math: true
---

## 前言

大三的寒假要结束了，突然想起来博客很久没更新了，于是特意维护了一下，更新了博客的一些配置。我还想在假期结束时写一点东西，又不太明确到底想写啥，考虑过很多，最终还是选择了机器学习。

虽然我看过一些机器学习内容，但是总感觉缺了点东西，希望能从 Andrew Ng 的课程中真正入门。本篇博客将作为我机器学习课程的笔记，部分用中文较难表述的词句我将使用英文原文。

## 第 1 周

第 1 周的内容比较简单，内容也非常少，分为课程介绍、单变量线性回归、线性代数复习三部分。

### 课程介绍

机器学习的定义：

- **非形式化定义**：不显式编程，使计算机具有学习能力的研究领域

- **形式化定义**：若计算机程序在任务 T 上的性能(由 P 衡量)用经验 E 来提高，则称该程序从经验 E 中学习任务 T 和性能度量 P

机器学习可以分为有监督学习和无监督学习两类：

- **有监督学习**：
  已知输入和输出，求从输入到输出的映射关系。有监督学习问题分为**回归**和**分类**问题。
  在回归问题中，输出是连续的值，如房价预测；在分类问题中，输出是离散的值，如图像分类。

- **无监督学习**：
  已知输入(无标签数据集)，求输入的内在结构。无监督学习问题分为**聚类**和**非聚类**问题。
  给定基因数据集，将其分为多类，是聚类问题；给定高维数据集，将其降至低维，是非聚类问题。

### 单变量线性回归

这一节简单讲解了有监督学习中的回归问题，以确定房价预测函数作为例子，先后完成了模型表示、确定代价函数、梯度下降寻找最优解三个步骤，笔记如下：

- **平方误差函数**：$$J(\theta_0,\theta_1)=\frac{1}{2m}\Sigma_{i=1}^{m}(h(x_i)-y_i)^{2}$$其中，$m$为样本容量，$x_i,y_i$为第$i$个样本的输入和输出，$h$为待定函数(自变量为$x$)，$\theta_0,\theta_1$为$h$的两个待定系数

- **梯度下降公式**：$$\Theta:=\Theta-\alpha\frac{\partial}{\partial\Theta}J(\Theta)$$其中，$:=$为赋值符号，$J$为代价函数，$\Theta$向量为$J$的参数，$\Theta$向量也是待定函数$h$的待定系数，$\alpha$为学习率

### 线性代数复习

这一节的内容是线性代数基础，给出了矩阵和向量的定义，并定义了矩阵的相关运算。由于内容过于基础，就不做笔记了。如有还未学习过线性代数的读者，我推荐观看[3Blue1Brown 的线性代数合集](https://www.bilibili.com/video/BV1ys411472E)。

## 第 2 周

第 2 周的标题是多变量梯度下降，包括多变量线性回归、解析法计算参数、Octave 语法入门三部分。

### 多变量线性回归

多变量线性回归的一些**公式**：

- **待定函数**为：$$H(X)=\Theta^{T}X$$其中，$\Theta$向量为待定系数，$X$向量为自变量

- **梯度下降公式**仍为：$$\Theta:=\Theta-\alpha\frac{\partial}{\partial\Theta}J(\Theta)$$其中，$:=$为赋值符号，$J$为代价函数，$\Theta$向量为$J$的参数，$\Theta$向量也是待定函数$H$的待定系数，$\alpha$为学习率

多变量线性回归的一些 **Trick**：

- 对于一些数据范围较大的特征，可以采用**特征缩放**将其归一化，加速梯度下降的收敛

- 学习率过大可能导致梯度下降不收敛，学习率过小则梯度下降收敛较慢

- 当线性回归拟合数据效果不好时，可以采用多项式回归

### 解析法计算参数

对于多变量线性回归，可以解析地计算出最优的$\Theta$向量，公式为：$$\Theta=(X^{T}X)^{-1}X^{T}y$$其中，$X$矩阵是$m \times (n+1)$的矩阵，每一行代表一个样本数据。$X$矩阵第 $1$ 列的元素均为 $1$，第$(n+1)$列表示第$n$个特征。$y$向量是列向量，$y$向量的第$n$个元素表示第$n$个样本对应的真实输出。

多变量线性回归问题，梯度下降法的时间复杂度是$O(kn^{2})$($k$为迭代次数)，而解析法计算的时间复杂度是$O(n^3)$。

若使用解析法计算参数时，发现矩阵$X^TX$不可逆，则可能发生了以下情况：

1. 特征重复，可能存在两个线性相关的特征，可以考虑消除这种线性相关性

2. 特征太多了($m \le n$)，可以考虑删除一些特征

### Octave/Matlab 入门

#### Octave/Matlab 的基础操作

- 算术运算：`+(加)`, `-(减)`, `*(乘)`, `/(除)`, `^(幂)`

- 数值比较：`==(等于)`, `~=(不等于)`, `>(大于)`, `<(小于)`, `>=(大于等于)`, `<=(小于等于)`

- 逻辑运算：`&&(逻辑与)`, `||(逻辑或)`, `xor(逻辑异或)`

- 一段代码示例：

  ```matlab
  a = pi; % 这是注释
  b = 'hi'; % 在语句后加;可以阻止REPL输出
  a % 输出a，也可使用disp(a)
  disp(sprintf('2 decimals: %0.2f', a)) % 输出2位小数
  format long % 设置REPL输出更长的数据
  ```

- 矩阵和向量的表示：

  ```matlab
  A = [1 2;3 4;5 6] % 定义一个3行2列的矩阵
  v = [1;2;3] % 定义一个列向量
  v = 1:0.1:2 % 定义一个行向量，行向量的元素为1, 1.1, 1.2, ..., 2
  v = 1:6 % 定义一个行向量，行向量的元素为1, 2, 3, ..., 6
  C = 2*ones(2,3) % 定义一个2行3列的全2矩阵
  w = zeros(1,3) % 定义一个1行3列的全0矩阵
  w = rand(1,3) % 定义一个1行3列的矩阵，元素均为0到1之间的随机数
  w = -6 + sqrt(10)*(randn(1,10000))
  hist(w,50) % 绘制w的直方图，50为直方图的组数
  I = eye(4) % 定义一个4阶单位矩阵
  ```

- 帮助命令：`help`

#### Octave/Matlab 的数据处理

- 查看矩阵/向量的维数：

  ```matlab
  A = [1 2; 3 4; 5 6]
  size(A) % 输出矩阵A的大小，结果为[3 2]
  size(A,1) % 输出矩阵A第一维的大小，结果为3
  v = [1 2 3 4]
  length(v) % 输出向量v的长度，结果为4
  length(A) % 输出矩阵A第一维的大小，结果为3
  ```

- 工作目录操作：

  ```matlab
  pwd % 输出当前目录
  cd 'C:\Users\Administrator\Desktop' % 切换到桌面
  ls % 显示当前目录下的文件
  mkdir 'test' % 在当前目录下创建一个文件夹
  rmdir 'test' % 删除当前目录下的文件夹
  ```

{% note secondary %}
.dat后缀的文件一般为数据文件，该后缀被多种软件所使用，每个软件定义的数据内容很可能不一样。下文中，.dat文件的内容为以空格分隔的数字，每行代表一个样本，每列代表一个特征。
{% endnote %}

- 数据载入相关操作：

  ```matlab
  A = load('data.dat') % 从data.dat文件中载入数据，结果为一个矩阵
  who % 输出当前会话的所有变量名
  whos % 输出当前会话的所有变量的详细信息
  clear A % 删除变量A
  v = A(1:10,1:2) % 取出矩阵A的第1行到第10行，第1列到第2列的元素
  save hello.mat v % 保存变量v到hello.mat文件中，该文件为二进制文件
  clear % 删除所有变量
  save hello.txt v -ascii % 保存变量v到hello.txt文件中，-ascii表示以ASCII码保存
  ```

- 矩阵/向量切片操作

  ```matlab
  A(3,2) % 输出矩阵A的第3行第2列的元素
  A(2,:) % 输出矩阵A的第2行的所有元素
  A([1 3],:) % 输出矩阵A的第1行和第3行的所有元素
  A(:,2) = [10; 11; 12] % 将矩阵A的第2列赋值为10, 11, 12
  A = [A, [100; 101; 102]] % 将列向量[100; 101; 102]添加到矩阵A的最后一列
  A(:) % 将矩阵A转换为列向量
  A = [1 2; 3 4]
  B = [5 6; 7 8]
  C = [A B] % 将矩阵A和B按行拼接，结果为[1 2 5 6; 3 4 7 8]，等价于[A, B]
  C = [A; B] % 将矩阵A和B按列拼接，结果为[1 2; 3 4; 5 6; 7 8]
  ```

#### Octave/Matlab 的矩阵运算

尚待施工

#### Octave/Matlab 的绘图

尚待施工

#### Octave/Matlab 的流程控制

尚待施工

#### Tips: 将计算向量化

尚待施工

## 参考资料

- Coursera：Andrew Ng[机器学习课程](https://www.coursera.org/learn/machine-learning)
- 知乎：[常用聚类算法](https://zhuanlan.zhihu.com/p/104355127)

由于作者水平有限，所以文章中难免有少数不严谨之处，如有读者发现此类疏忽，恳请读者指出。另外，如果认为本文对您有帮助，欢迎请作者喝咖啡！![Matrix53的微信赞赏码](/img/global/wxQRcode_pay.png)
